{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision.models\n",
    "from PIL import Image\n",
    "import numpy as nps\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.autoencoder import *\n",
    "from lib.attention_model import AttentionLayer, MultiAttentionLayer\n",
    "from lib.correspondence_datamodule import CorrespondenceDataModule\n",
    "from lib.warping import *\n",
    "from externals.d2net.lib.utils import *\n",
    "from lib.loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a new training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.77s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the validation dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.09s/it]\n"
     ]
    }
   ],
   "source": [
    "megadepth_path = \"/mnt/c/Users/phill/polybox/Deep Learning/MegaDepthDataset\"\n",
    "data_module = CorrespondenceDataModule(base_path=megadepth_path, batch_size=1)\n",
    "data_module.prepare_data()\n",
    "data_module.setup(stage='fit')\n",
    "dl_train = data_module.train_dataloader()\n",
    "dl_val = data_module.val_dataloader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"image1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu cpu cpu\n",
      "cpu cpu cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([nan], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DistinctivenessLoss()(x1_encoded, x2_encoded, y1, y2, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Failed to find a mapping for bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.3.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.3.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.3.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.3.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.3.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.3.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.4.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.4.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.4.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.5.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.5.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.5.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for fc.weight\n",
      "WARNING:absl:Failed to find a mapping for fc.bias\n",
      "WARNING:absl:Failed to find a mapping for bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer1.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.3.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.3.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer2.3.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.3.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.3.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.3.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.4.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.4.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.4.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.5.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.5.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer3.5.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.0.downsample.1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.1.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.1.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.1.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.2.bn1.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.2.bn2.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for layer4.2.bn3.num_batches_tracked\n",
      "WARNING:absl:Failed to find a mapping for fc.weight\n",
      "WARNING:absl:Failed to find a mapping for fc.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 16, 16])\n",
      "torch.Size([1, 96, 16, 16])\n",
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "x1 = batch['image1']\n",
    "x2 = batch[\"image2\"]\n",
    "feature_encoder = FeatureEncoder3().load_from_checkpoint(\"lightning_logs/version_3/checkpoints/epoch=50-step=7394.ckpt\").requires_grad_(False)\n",
    "attention_model = AttentionLayer(feature_encoder)\n",
    "attention_model.freeze()\n",
    "with torch.no_grad():\n",
    "    x1_encoded = attention_model.concat_layers(attention_model.feature_encoder.forward(x1)) #bx48x32x32\n",
    "    x2_encoded = attention_model.concat_layers(attention_model.feature_encoder.forward(x2))\n",
    "\n",
    "\n",
    "print(x1_encoded.shape)\n",
    "print(x2_encoded.shape)\n",
    "x1_encoded.requires_grad = False\n",
    "x2_encoded.requires_grad = False\n",
    "y1 = attention_model.forward(batch[\"image1\"]) #bx1x32x32\n",
    "y2 = attention_model.forward(batch[\"image2\"])\n",
    "\n",
    "print(y1.shape)\n",
    "print(y2.shape)\n",
    "\n",
    "\n",
    "\n",
    "# print(x1_encoded[0,0,0,0])\n",
    "\n",
    "# print(loss)\n",
    "# print(loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0 cuda:0\n",
      "cuda:0 cuda:0 cuda:0\n",
      "torch.Size([48, 338]) torch.Size([48, 338]) torch.Size([48, 1024]) torch.Size([48, 1024])\n",
      "torch.Size([338])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-04c01146760e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDistinctivenessLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e8144a6f6ad6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1_encoded, x2_encoded, attentions1, attentions2, correspondences)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrespondences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinctiveness_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrespondences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdistinctiveness_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrespondences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \"\"\"\n",
      "\u001b[0;32m<ipython-input-63-e8144a6f6ad6>\u001b[0m in \u001b[0;36mdistinctiveness_loss\u001b[0;34m(self, x1_encoded, x2_encoded, attentions1, attentions2, correspondences, idx)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mtarget1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;31m#print(torch.mean(torch.cdist(scores1,))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[0.9041,  0.0196], [-0.3108, -2.4423], [-0.4821,  1.059]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit03d3002403754c398b1cb8f8a691cb17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
