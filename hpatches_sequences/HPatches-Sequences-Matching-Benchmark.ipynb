{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete cache of our-model\n",
    "file = 'cache/our-model.npy'\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "    print('file removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new methods here.\n",
    "# methods = ['hesaff', 'hesaffnet', 'delf', 'delf-new', 'superpoint', 'd2-net', 'd2-net-trained']\n",
    "# names = ['Hes. Aff. + Root-SIFT', 'HAN + HN++', 'DELF', 'DELF New', 'SuperPoint', 'D2-Net', 'D2-Net Trained']\n",
    "# colors = ['black', 'orange', 'red', 'red', 'blue', 'purple', 'purple']\n",
    "# linestyles = ['-', '-', '-', '--', '-', '-', '--']\n",
    "methods = ['our-model', 'hesaff', 'hesaffnet', 'delf', 'delf-new', 'superpoint', 'lf-net', 'd2-net', 'd2-net-ms', 'd2-net-trained', 'd2-net-trained-ms']\n",
    "names = ['OUR-MODEL', 'Hes. Aff. + Root-SIFT', 'HAN + HN++', 'DELF', 'DELF New', 'SuperPoint', 'LF-Net', 'D2-Net', 'D2-Net MS', 'D2-Net Trained', 'D2-Net Trained MS']\n",
    "colors = ['pink', 'black', 'orange', 'red', 'red', 'blue', 'brown', 'purple', 'green', 'purple', 'green']\n",
    "linestyles = ['-', '-', '-', '-', '--', '-', '-', '-', '-', '--', '--']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here if you want to use top K or all features.\n",
    "# top_k = 2000\n",
    "top_k = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i = 52\n",
    "n_v = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'hpatches-sequences-release'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = [1, 15]\n",
    "rng = np.arange(lim[0], lim[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnn_matcher(descriptors_a, descriptors_b):\n",
    "    device = descriptors_a.device\n",
    "    sim = descriptors_a @ descriptors_b.t()\n",
    "    nn12 = torch.max(sim, dim=1)[1]\n",
    "    nn21 = torch.max(sim, dim=0)[1]\n",
    "    ids1 = torch.arange(0, sim.shape[0], device=device)\n",
    "    mask = (ids1 == nn21[nn12])\n",
    "    matches = torch.stack([ids1[mask], nn12[mask]])\n",
    "    return matches.t().data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_features(read_feats):\n",
    "    seq_names = sorted(os.listdir(dataset_path))\n",
    "\n",
    "    n_feats = []\n",
    "    n_matches = []\n",
    "    seq_type = []\n",
    "    i_err = {thr: 0 for thr in rng}\n",
    "    v_err = {thr: 0 for thr in rng}\n",
    "\n",
    "    for seq_idx, seq_name in tqdm(enumerate(seq_names), total=len(seq_names)):\n",
    "        keypoints_a, descriptors_a = read_feats(seq_name, 1)\n",
    "        n_feats.append(keypoints_a.shape[0])\n",
    "\n",
    "        for im_idx in range(2, 7):\n",
    "            keypoints_b, descriptors_b = read_feats(seq_name, im_idx)\n",
    "            n_feats.append(keypoints_b.shape[0])\n",
    "\n",
    "            matches = mnn_matcher(\n",
    "                torch.from_numpy(descriptors_a).to(device=device), \n",
    "                torch.from_numpy(descriptors_b).to(device=device)\n",
    "            )\n",
    "            \n",
    "            homography = np.loadtxt(os.path.join(dataset_path, seq_name, \"H_1_\" + str(im_idx)))\n",
    "            \n",
    "            pos_a = keypoints_a[matches[:, 0], : 2] \n",
    "            pos_a_h = np.concatenate([pos_a, np.ones([matches.shape[0], 1])], axis=1)\n",
    "            pos_b_proj_h = np.transpose(np.dot(homography, np .transpose(pos_a_h)))\n",
    "            pos_b_proj = pos_b_proj_h[:, : 2] / pos_b_proj_h[:, 2 :]\n",
    "\n",
    "            pos_b = keypoints_b[matches[:, 1], : 2]\n",
    "\n",
    "            dist = np.sqrt(np.sum((pos_b - pos_b_proj) ** 2, axis=1))\n",
    "\n",
    "            n_matches.append(matches.shape[0])\n",
    "            seq_type.append(seq_name[0])\n",
    "            \n",
    "            if dist.shape[0] == 0:\n",
    "                dist = np.array([float(\"inf\")])\n",
    "            \n",
    "            for thr in rng:\n",
    "                if seq_name[0] == 'i':\n",
    "                    i_err[thr] += np.mean(dist <= thr)\n",
    "                else:\n",
    "                    v_err[thr] += np.mean(dist <= thr)\n",
    "    \n",
    "    seq_type = np.array(seq_type)\n",
    "    n_feats = np.array(n_feats)\n",
    "    n_matches = np.array(n_matches)\n",
    "    \n",
    "    return i_err, v_err, [seq_type, n_feats, n_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(stats):\n",
    "    seq_type, n_feats, n_matches = stats\n",
    "    print('# Features: {:f} - [{:d}, {:d}]'.format(np.mean(n_feats), np.min(n_feats), np.max(n_feats)))\n",
    "    print('# Matches: Overall {:f}, Illumination {:f}, Viewpoint {:f}'.format(\n",
    "        np.sum(n_matches) / ((n_i + n_v) * 5), \n",
    "        np.sum(n_matches[seq_type == 'i']) / (n_i * 5), \n",
    "        np.sum(n_matches[seq_type == 'v']) / (n_v * 5))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_read_function(method, extension='ppm'):\n",
    "    def read_function(seq_name, im_idx):\n",
    "        aux = np.load(os.path.join(dataset_path, seq_name, '%d.%s.%s' % (im_idx, extension, method)))\n",
    "        if top_k is None:\n",
    "            return aux['keypoints'], aux['descriptors']\n",
    "        else:\n",
    "            assert('scores' in aux)\n",
    "            ids = np.argsort(aux['scores'])[-top_k :]\n",
    "            return aux['keypoints'][ids, :], aux['descriptors'][ids, :]\n",
    "    return read_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_to_rootsift(descriptors):\n",
    "    return np.sqrt(descriptors / np.expand_dims(np.sum(np.abs(descriptors), axis=1), axis=1) + 1e-16)\n",
    "def parse_mat(mat):\n",
    "    keypoints = mat['keypoints'][:, : 2]\n",
    "    raw_descriptors = mat['descriptors']\n",
    "    l2_norm_descriptors = raw_descriptors / np.expand_dims(np.sum(raw_descriptors ** 2, axis=1), axis=1)\n",
    "    descriptors = sift_to_rootsift(l2_norm_descriptors)\n",
    "    if top_k is None:\n",
    "        return keypoints, descriptors\n",
    "    else:\n",
    "        assert('scores' in mat)\n",
    "        ids = np.argsort(mat['scores'][0])[-top_k :]\n",
    "        return keypoints[ids, :], descriptors[ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if top_k is None:\n",
    "    cache_dir = 'cache'\n",
    "else:\n",
    "    cache_dir = 'cache-top'\n",
    "if not os.path.isdir(cache_dir):\n",
    "    os.mkdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-c422a9e210ef>:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for seq_idx, seq_name in tqdm(enumerate(seq_names), total=len(seq_names)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2bd4a8b88a4aba93c9ef8e5182229c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hpatches-sequences-release/i_ajuntament/1.ppm.our-model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ea792f63b18f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c422a9e210ef>\u001b[0m in \u001b[0;36mbenchmark_features\u001b[0;34m(read_feats)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseq_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mkeypoints_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptors_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mn_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-6f4afbb04831>\u001b[0m in \u001b[0;36mread_function\u001b[0;34m(seq_name, im_idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_read_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ppm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%d.%s.%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtop_k\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keypoints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'descriptors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hpatches-sequences-release/i_ajuntament/1.ppm.our-model'"
     ]
    }
   ],
   "source": [
    "for method in methods:\n",
    "    output_file = os.path.join(cache_dir, method + '.npy')\n",
    "    print(method)\n",
    "    if method == 'hesaff':\n",
    "        read_function = lambda seq_name, im_idx: parse_mat(loadmat(os.path.join(dataset_path, seq_name, '%d.ppm.hesaff' % im_idx), appendmat=False))\n",
    "    else:\n",
    "        if method == 'delf' or method == 'delf-new':\n",
    "            read_function = generate_read_function(method, extension='png')\n",
    "        else:\n",
    "            read_function = generate_read_function(method)\n",
    "    if os.path.exists(output_file):\n",
    "        print('Loading precomputed errors...')\n",
    "        errors[method] = np.load(output_file, allow_pickle=True)\n",
    "    else:\n",
    "        errors[method] = benchmark_features(read_function)\n",
    "        np.save(output_file, errors[method])\n",
    "    summary(errors[method][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_lim = [1, 10]\n",
    "plt_rng = np.arange(plt_lim[0], plt_lim[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=25)\n",
    "plt.rc('axes', labelsize=25)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    i_err, v_err, _ = errors[method]\n",
    "    plt.plot(plt_rng, [(i_err[thr] + v_err[thr]) / ((n_i + n_v) * 5) for thr in plt_rng], color=color, ls=ls, linewidth=3, label=name)\n",
    "plt.title('Overall')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylabel('MMA')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    i_err, v_err, _ = errors[method]\n",
    "    plt.plot(plt_rng, [i_err[thr] / (n_i * 5) for thr in plt_rng], color=color, ls=ls, linewidth=3, label=name)\n",
    "plt.title('Illumination')\n",
    "plt.xlabel('threshold [px]')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylim([0, 1])\n",
    "plt.gca().axes.set_yticklabels([])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    i_err, v_err, _ = errors[method]\n",
    "    plt.plot(plt_rng, [v_err[thr] / (n_v * 5) for thr in plt_rng], color=color, ls=ls, linewidth=3, label=name)\n",
    "plt.title('Viewpoint')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylim([0, 1])\n",
    "plt.gca().axes.set_yticklabels([])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "if top_k is None:\n",
    "    plt.savefig('hseq.pdf', bbox_inches='tight', dpi=300)\n",
    "else:\n",
    "    plt.savefig('hseq-top.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
